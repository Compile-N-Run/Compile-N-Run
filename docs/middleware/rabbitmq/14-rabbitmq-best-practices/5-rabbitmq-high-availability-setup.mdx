---
title: RabbitMQ High Availability Setup
description: Learn how to configure RabbitMQ for high availability to ensure your messaging system remains operational even during hardware or network failures.

---

# RabbitMQ High Availability Setup

## Introduction

When building production-ready applications, ensuring your messaging system remains operational even during hardware failures or network issues is critical. RabbitMQ, a popular open-source message broker, provides several high availability (HA) options to help you create resilient messaging infrastructures.

In this guide, we'll explore how to set up RabbitMQ for high availability, covering clustering, mirrored queues, and quorum queues. By the end, you'll understand how to implement a robust RabbitMQ setup that can withstand various failure scenarios.

## Understanding RabbitMQ High Availability Concepts

Before diving into implementation, let's understand some key concepts:

### What is High Availability?

High availability refers to a system's ability to continue functioning even when some of its components fail. For RabbitMQ, this means ensuring that your message broker remains operational and accessible even if individual nodes experience problems.

### Why is HA Important for RabbitMQ?

RabbitMQ often serves as a critical communication layer between different services in your architecture. If RabbitMQ goes down:

- Messages may be lost
- Services dependent on messaging might stop functioning
- Your entire application could experience downtime

### Key RabbitMQ HA Components

RabbitMQ offers several mechanisms for high availability:

1. **Clustering**: Connecting multiple RabbitMQ servers to work as a single logical broker
2. **Queue Mirroring**: Replicating queues across multiple nodes
3. **Quorum Queues**: A more modern alternative to mirrored queues with better failure handling
4. **Federation**: Connecting brokers across WANs or different data centers
5. **Shovel**: Moving messages between brokers

Let's explore each of these in detail.

## Setting Up a RabbitMQ Cluster

The foundation of RabbitMQ high availability is clustering. A cluster consists of multiple RabbitMQ nodes that share users, virtual hosts, queues, exchanges, bindings, and runtime parameters.

### Prerequisites

- Multiple servers/VMs with RabbitMQ installed (minimum 3 for proper HA)
- Erlang cookie shared across all nodes
- Network connectivity between all nodes
- Same RabbitMQ version across all nodes

### Step 1: Configure the Erlang Cookie

RabbitMQ nodes use an Erlang cookie for authentication between cluster nodes. The cookie must be identical on all nodes.

On each node, locate and edit the `.erlang.cookie` file:

```bash
# On Linux/macOS, usually in:
sudo nano /var/lib/rabbitmq/.erlang.cookie

# On Windows, usually in:
# C:\Windows\system32\config\systemprofile\.erlang.cookie
```

Set the same value on all nodes, then restart RabbitMQ on each node:

```bash
sudo service rabbitmq-server restart
```

### Step 2: Create the Cluster

1. Start RabbitMQ on all nodes.
2. Choose one node as the first node (e.g., rabbit1).
3. On the second node (rabbit2), run:

```bash
# Stop the RabbitMQ application (but not the Erlang node)
sudo rabbitmqctl stop_app

# Join the cluster
sudo rabbitmqctl join_cluster rabbit@rabbit1

# Start the application again
sudo rabbitmqctl start_app
```

4. Repeat for the third node (rabbit3):

```bash
sudo rabbitmqctl stop_app
sudo rabbitmqctl join_cluster rabbit@rabbit1
sudo rabbitmqctl start_app
```

### Step 3: Verify Cluster Status

Check that your cluster is properly formed:

```bash
sudo rabbitmqctl cluster_status
```

You should see all nodes listed in the cluster.

### Visualizing the Cluster Formation

```mermaid
graph TD
    A[Node 1: rabbit1] --- B[Node 2: rabbit2]
    A --- C[Node 3: rabbit3]
    B --- C
    
    style A fill:#c0e5ff,stroke:#333,stroke-width:2px
    style B fill:#c0e5ff,stroke:#333,stroke-width:2px
    style C fill:#c0e5ff,stroke:#333,stroke-width:2px
```

## Implementing Queue Mirroring

While clustering distributes the broker's operations, it doesn't automatically replicate queue contents. For that, we need queue mirroring.

### Classic Mirrored Queues

Classic mirrored queues replicate queue contents across multiple nodes.

### Step 1: Enable Mirroring Policy

Use the `rabbitmqctl` command or the Management UI to set up mirroring policies:

```bash
# Mirror all queues starting with "ha." across all nodes
sudo rabbitmqctl set_policy ha-all "^ha\." '{"ha-mode":"all"}'

# Mirror specific queues to exactly 2 nodes
sudo rabbitmqctl set_policy ha-two "^two\." '{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}'
```

Or using the HTTP API:

```bash
curl -u admin:admin -X PUT "http://localhost:15672/api/policies/%2f/ha-all" \
  -H "Content-Type: application/json" \
  -d '{"pattern":"^ha\.", "definition":{"ha-mode":"all"}}'
```

### Understanding HA Policies

RabbitMQ offers several mirroring strategies:

- **ha-mode=all**: Mirror to all nodes in the cluster
- **ha-mode=exactly, ha-params=N**: Mirror to exactly N nodes
- **ha-mode=nodes, ha-params=["rabbit@node1", ...]**: Mirror to specific nodes

### Synchronization Modes

You can configure how queue contents synchronize:

- **ha-sync-mode=manual**: New mirrors start empty and sync manually
- **ha-sync-mode=automatic**: New mirrors sync automatically (can impact performance)

Example policy with synchronization:

```bash
sudo rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all","ha-sync-mode":"automatic"}'
```

## Quorum Queues: Modern High Availability

Quorum queues are a more modern alternative to classic mirrored queues, offering better safety guarantees and failure handling. They use the Raft consensus algorithm to ensure consistency.

### Step 1: Enable Quorum Queues

Quorum queues are available in RabbitMQ 3.8.0 and later. They're created by setting the queue type to `quorum`:

Using the Java client:

```java
Map<String, Object> args = new HashMap<>();
args.put("x-queue-type", "quorum");
channel.queueDeclare("my-quorum-queue", true, false, false, args);
```

Using the Management UI, when declaring a queue:
1. Set "Type" to "quorum"
2. Ensure "Durable" is checked (quorum queues must be durable)

### Step 2: Configure Replication Factor

Set the desired number of replicas:

```java
args.put("x-quorum-initial-group-size", 3);
channel.queueDeclare("my-quorum-queue", true, false, false, args);
```

### Quorum vs. Mirrored Queues

```mermaid
graph TD
    subgraph "Classic Mirrored Queue"
        M[Master] --> S1[Slave 1]
        M --> S2[Slave 2]
    end
    
    subgraph "Quorum Queue"
        L[Leader] --- F1[Follower 1]
        L --- F2[Follower 2]
        F1 --- F2
    end
    
    style M fill:#ffcccc,stroke:#333,stroke-width:2px
    style S1 fill:#ffdddd,stroke:#333,stroke-width:2px
    style S2 fill:#ffdddd,stroke:#333,stroke-width:2px
    
    style L fill:#ccffcc,stroke:#333,stroke-width:2px
    style F1 fill:#ddffdd,stroke:#333,stroke-width:2px
    style F2 fill:#ddffdd,stroke:#333,stroke-width:2px
```

## Federation and Shovel: Multi-Datacenter HA

For high availability across data centers or wide-area networks, RabbitMQ offers Federation and Shovel plugins.

### Federation Plugin

Federation allows exchanges and queues to transmit messages across multiple brokers or clusters.

#### Step 1: Enable the Federation Plugin

```bash
sudo rabbitmq-plugins enable rabbitmq_federation
sudo rabbitmq-plugins enable rabbitmq_federation_management
```

#### Step 2: Define an Upstream

```bash
# Define the upstream broker
sudo rabbitmqctl set_parameter federation-upstream my-upstream \
  '{"uri":"amqp://username:password@remote-host:5672","expires":3600000}'

# Create a policy to federate all exchanges
sudo rabbitmqctl set_policy federate-all ".*" \
  '{"federation-upstream-set":"all"}' \
  --apply-to exchanges
```

### Shovel Plugin

Shovel moves messages from a source to a destination queue, even across clusters or data centers.

#### Step 1: Enable the Shovel Plugin

```bash
sudo rabbitmq-plugins enable rabbitmq_shovel
sudo rabbitmq-plugins enable rabbitmq_shovel_management
```

#### Step 2: Define a Shovel

```bash
# Define a static shovel
sudo rabbitmqctl set_parameter shovel my-shovel \
  '{"src-uri":"amqp://","src-queue":"source-queue","dest-uri":"amqp://remote-host","dest-queue":"dest-queue"}'
```

## Handling Network Partitions

Network partitions (or "split-brain" scenarios) occur when nodes can't communicate but continue operating independently. RabbitMQ offers several partition handling strategies.

### Configuring Partition Handling

Edit the `rabbitmq.conf` file to set the partition handling mode:

```
# Automatically recover from partitions (prefer availability)
cluster_partition_handling = autoheal

# OR pause minority nodes (prefer consistency)
cluster_partition_handling = pause_minority
```

Options include:
- **ignore**: Do nothing (unsafe for production)
- **autoheal**: Automatically decide which nodes should restart
- **pause_minority**: Stop minority side nodes until reconnection
- **pause_if_all_down**: Pause nodes if specified nodes are down

## Real-World Example: Implementing a Complete HA Setup

Let's put everything together with a real-world example of setting up a production-grade RabbitMQ HA cluster.

### Scenario

- 3 node RabbitMQ cluster (rabbit1, rabbit2, rabbit3)
- Critical queues using quorum queues
- Less critical queues using mirrored queues
- Cross-datacenter replication using federation

### Implementation Steps

1. **Set up the 3-node cluster** as described earlier.

2. **Configure partition handling**:

```
# In rabbitmq.conf on all nodes
cluster_partition_handling = pause_minority
```

3. **Set up policies for different queue types**:

```bash
# Critical queues - use quorum queues
sudo rabbitmqctl set_policy critical-queues "^critical\." \
  '{"queue-type":"quorum","ha-mode":"all"}' \
  --apply-to queues

# Standard queues - use mirrored queues
sudo rabbitmqctl set_policy standard-queues "^standard\." \
  '{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}' \
  --apply-to queues
```

4. **Configure federation** for cross-datacenter replication:

```bash
# Enable the plugin
sudo rabbitmq-plugins enable rabbitmq_federation
sudo rabbitmq-plugins enable rabbitmq_federation_management

# Define the upstream (DC2)
sudo rabbitmqctl set_parameter federation-upstream dc2 \
  '{"uri":"amqp://username:password@dc2-rabbit1:5672","expires":3600000}'

# Federate important exchanges
sudo rabbitmqctl set_policy federate-important "^important\." \
  '{"federation-upstream-set":"all"}' \
  --apply-to exchanges
```

5. **Configure load balancer** in front of the cluster (e.g., HAProxy).

### HAProxy Configuration Example

```
frontend rabbitmq_front
    bind *:5672
    mode tcp
    default_backend rabbitmq_back

backend rabbitmq_back
    mode tcp
    balance roundrobin
    option tcp-check
    server rabbit1 rabbit1:5672 check
    server rabbit2 rabbit2:5672 check
    server rabbit3 rabbit3:5672 check
```

### Client Connection Example (Node.js)

When connecting clients to a highly available RabbitMQ cluster, use connection retry logic:

```javascript
const amqp = require('amqplib');

async function connectWithRetry() {
  const maxRetries = 10;
  let retries = 0;
  
  while (retries < maxRetries) {
    try {
      // Connect to the load balancer in front of RabbitMQ cluster
      const connection = await amqp.connect('amqp://username:password@load-balancer:5672');
      console.log('Connected to RabbitMQ');
      
      // Set up channel
      const channel = await connection.createChannel();
      
      // Handle connection close
      connection.on('close', (err) => {
        console.error('Connection closed, reconnecting...', err);
        setTimeout(connectWithRetry, 5000);
      });
      
      return channel;
    } catch (error) {
      console.error('Connection failed, retrying...', error);
      retries++;
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }
  
  throw new Error('Failed to connect to RabbitMQ after multiple retries');
}

// Usage
async function main() {
  try {
    const channel = await connectWithRetry();
    
    // Declare a quorum queue
    await channel.assertQueue('critical.orders', {
      durable: true,
      arguments: {
        'x-queue-type': 'quorum'
      }
    });
    
    // Rest of the application logic
  } catch (error) {
    console.error('Failed to start application:', error);
    process.exit(1);
  }
}

main();
```

## Monitoring a Highly Available RabbitMQ Cluster

To ensure your HA setup is functioning correctly, implement proper monitoring.

### Key Metrics to Monitor

1. **Node status**: Are all nodes up and connected?
2. **Queue replication**: Are queues properly replicated?
3. **Message rates**: Publishing, delivery, acknowledgment rates
4. **Resource usage**: CPU, memory, disk space
5. **Network partitions**: Any active network partitions?

### Monitoring Tools

1. **RabbitMQ Management Plugin**: Built-in web UI and HTTP API
2. **Prometheus + Grafana**: Using the RabbitMQ Prometheus plugin
3. **Commercial monitoring tools**: Datadog, New Relic, etc.

### Example Prometheus Configuration

Enable the Prometheus plugin:

```bash
sudo rabbitmq-plugins enable rabbitmq_prometheus
```

Prometheus configuration snippet:

```yaml
scrape_configs:
  - job_name: 'rabbitmq'
    static_configs:
      - targets: ['rabbit1:15692', 'rabbit2:15692', 'rabbit3:15692']
```

## Handling Failure Scenarios

Let's examine common failure scenarios and how a properly configured HA setup responds:

### Scenario 1: Single Node Failure

**What happens**: One node in a 3-node cluster fails.

**Result with HA**:
- Quorum queues: Continue operating if the majority of nodes (2/3) are available
- Mirrored queues: If the master fails, a mirror is promoted to master
- Clients: Automatically reconnect through the load balancer to available nodes

### Scenario 2: Network Partition

**What happens**: Network issues split the cluster into two parts that can't communicate.

**Result with pause_minority**:
- The minority side pauses operations
- The majority side continues processing
- When network is restored, the minority rejoins automatically

### Scenario 3: Datacenter Failure

**What happens**: An entire datacenter goes offline.

**Result with Federation/Shovel**:
- Messages continue to be processed in the available datacenter
- When the failed datacenter recovers, federation/shovel reconnects and syncs

## Best Practices for Production

To ensure your RabbitMQ HA setup is production-ready:

1. **Use at least 3 nodes** for proper quorum and failure tolerance
2. **Distribute nodes** across availability zones or racks
3. **Choose the right queue type**:
   - Quorum queues for critical workloads
   - Classic mirrored queues for backward compatibility
4. **Implement proper client reconnection** logic
5. **Monitor all aspects** of your cluster
6. **Test failure scenarios** regularly
7. **Back up configurations** and definitions
8. **Use TLS** for secure communication
9. **Implement proper resource limits** to prevent overload

## Summary

In this guide, we covered:

1. **RabbitMQ clustering**: The foundation of HA
2. **Queue mirroring**: Replicating queue contents across nodes
3. **Quorum queues**: Modern, consensus-based HA queues
4. **Federation and Shovel**: Cross-datacenter replication
5. **Handling network partitions**: Maintaining consistency during network issues
6. **Real-world implementation**: A complete production setup
7. **Monitoring**: Ensuring your HA setup works properly
8. **Failure scenarios**: How the system handles various failures

By implementing these high availability strategies, you can create a robust RabbitMQ messaging system that remains operational even during hardware failures, network issues, or datacenter outages.

## Additional Resources

To further your understanding of RabbitMQ high availability:

- [RabbitMQ Clustering Guide](https://www.rabbitmq.com/clustering.html)
- [RabbitMQ Quorum Queues Documentation](https://www.rabbitmq.com/quorum-queues.html)
- [RabbitMQ Federation Plugin](https://www.rabbitmq.com/federation.html)
- [RabbitMQ Shovel Plugin](https://www.rabbitmq.com/shovel.html)

## Exercises

1. Set up a 3-node RabbitMQ cluster in Docker containers and verify the cluster status.
2. Create a quorum queue and test what happens when you stop one of the nodes.
3. Implement federation between two separate RabbitMQ clusters.
4. Write a client application that can reconnect automatically when nodes fail.
5. Simulate a network partition and observe how different partition handling strategies behave.