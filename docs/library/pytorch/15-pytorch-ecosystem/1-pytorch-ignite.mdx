---
title: PyTorch Ignite
description: Learn about PyTorch Ignite - a high-level library that helps with training and evaluating neural networks in PyTorch flexibly and transparently.

---

# PyTorch Ignite

## Introduction

PyTorch Ignite is a high-level library built on top of PyTorch that helps simplify the process of training and evaluating neural networks. It provides a lightweight wrapper around PyTorch that removes much of the boilerplate code while maintaining flexibility. Ignite is designed to make your code more readable, reusable, and maintainable without sacrificing control over the training process.

In this tutorial, we'll explore PyTorch Ignite's key features and learn how to use it for training deep learning models. We'll cover the core concepts, demonstrate basic usage patterns, and show how Ignite can streamline your PyTorch workflow.

## Why Use PyTorch Ignite?

When training neural networks with vanilla PyTorch, you often need to write repetitive code for:

- Training and validation loops
- Metric calculation
- Checkpointing models
- Early stopping
- Logging and visualization

Ignite abstracts these common tasks while allowing you to customize every aspect of your training pipeline. Key benefits include:

1. **Reduced boilerplate code**: Focus on model architecture instead of training loops
2. **Built-in metrics**: Easy tracking of accuracy, loss, and other metrics
3. **Event system**: Elegant handling of training events
4. **Extensibility**: Simple creation of custom components

## Installation

Before we begin, make sure you have PyTorch Ignite installed:

```bash
pip install pytorch-ignite
```

## Core Concepts

PyTorch Ignite revolves around several core concepts:

### 1. Engine

The `Engine` is the central component that manages the training or evaluation loop. It runs a given `process_function` over a data iterator.

### 2. Events and Event Handlers

Ignite uses an event-driven paradigm where you can attach functions to specific events in the training cycle (like epoch start/end, iteration start/end).

### 3. Metrics

Built-in classes to compute various performance metrics during training and validation.

### 4. Handlers

Utility functions that can be attached to the engine to perform common tasks like model checkpointing, early stopping, etc.

## Basic Usage: Training a Simple Model

Let's start by training a simple neural network on the MNIST dataset using PyTorch Ignite:

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator
from ignite.metrics import Accuracy, Loss

# Define the neural network
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)
        self.relu = nn.ReLU()
        self.max_pool = nn.MaxPool2d(2)

    def forward(self, x):
        x = self.relu(self.max_pool(self.conv1(x)))
        x = self.relu(self.max_pool(self.conv2(x)))
        x = x.view(-1, 320)
        x = self.relu(self.fc1(x))
        return self.fc2(x)

# Set up data loaders
train_dataset = MNIST(download=True, root=".", transform=ToTensor())
val_dataset = MNIST(download=True, root=".", train=False, transform=ToTensor())

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=128)

# Set up model, optimizer and loss function
model = SimpleNet()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
criterion = nn.CrossEntropyLoss()

# Create trainer and evaluator engines
trainer = create_supervised_trainer(model, optimizer, criterion, device='cpu')
evaluator = create_supervised_evaluator(model, 
                                       metrics={
                                           'accuracy': Accuracy(),
                                           'loss': Loss(criterion)
                                       }, 
                                       device='cpu')

# Add event handlers
@trainer.on(Events.EPOCH_COMPLETED)
def log_training_results(trainer):
    evaluator.run(train_loader)
    metrics = evaluator.state.metrics
    print(f"Training - Epoch: {trainer.state.epoch} "
          f"Avg accuracy: {metrics['accuracy']:.2f} "
          f"Avg loss: {metrics['loss']:.2f}")

@trainer.on(Events.EPOCH_COMPLETED)
def log_validation_results(trainer):
    evaluator.run(val_loader)
    metrics = evaluator.state.metrics
    print(f"Validation - Epoch: {trainer.state.epoch} "
          f"Avg accuracy: {metrics['accuracy']:.2f} "
          f"Avg loss: {metrics['loss']:.2f}")

# Run the training for 5 epochs
trainer.run(train_loader, max_epochs=5)
```

The above code will output something like:

```
Training - Epoch: 1 Avg accuracy: 0.91 Avg loss: 0.28
Validation - Epoch: 1 Avg accuracy: 0.94 Avg loss: 0.19
Training - Epoch: 2 Avg accuracy: 0.97 Avg loss: 0.09
Validation - Epoch: 2 Avg accuracy: 0.97 Avg loss: 0.11
...
```

## Building Custom Training Loops

Instead of using the built-in `create_supervised_trainer`, you can create your own training function for more control:

```python
from ignite.engine import Engine

def train_step(engine, batch):
    model.train()
    optimizer.zero_grad()
    x, y = batch
    y_pred = model(x)
    loss = criterion(y_pred, y)
    loss.backward()
    optimizer.step()
    return loss.item()

trainer = Engine(train_step)

# Run the training
trainer.run(train_loader, max_epochs=5)
```

## Tracking Multiple Metrics

Ignite makes it easy to track different metrics during training:

```python
from ignite.metrics import Accuracy, Loss, Precision, Recall

evaluator = create_supervised_evaluator(
    model,
    metrics={
        'accuracy': Accuracy(),
        'loss': Loss(criterion),
        'precision': Precision(),
        'recall': Recall()
    },
    device='cpu'
)

@trainer.on(Events.EPOCH_COMPLETED)
def log_metrics(trainer):
    evaluator.run(val_loader)
    metrics = evaluator.state.metrics
    print(f"Epoch {trainer.state.epoch} - "
          f"Accuracy: {metrics['accuracy']:.4f}, "
          f"Loss: {metrics['loss']:.4f}, "
          f"Precision: {metrics['precision']:.4f}, "
          f"Recall: {metrics['recall']:.4f}")
```

## Model Checkpointing

Ignite provides handlers for saving model checkpoints based on different criteria:

```python
from ignite.handlers import ModelCheckpoint

# Save the model after every epoch
checkpoint_handler = ModelCheckpoint(
    'checkpoints', 
    'mnist_model', 
    n_saved=2, 
    require_empty=False
)

trainer.add_event_handler(
    Events.EPOCH_COMPLETED, 
    checkpoint_handler, 
    {'model': model}
)

# Save based on validation accuracy
best_model_handler = ModelCheckpoint(
    'best_models', 
    'best_acc', 
    n_saved=1, 
    score_function=lambda engine: engine.state.metrics['accuracy'],
    score_name="accuracy",
    require_empty=False
)

evaluator.add_event_handler(
    Events.COMPLETED, 
    best_model_handler, 
    {'model': model}
)
```

## Early Stopping

To prevent overfitting, you can use early stopping:

```python
from ignite.handlers import EarlyStopping

def score_function(engine):
    val_loss = engine.state.metrics['loss']
    return -val_loss  # Return negative because we want to maximize the score

early_stopping_handler = EarlyStopping(
    patience=3, 
    score_function=score_function, 
    trainer=trainer
)

evaluator.add_event_handler(Events.COMPLETED, early_stopping_handler)
```

## Integrating with TensorBoard

Ignite works well with TensorBoard for tracking and visualizing your metrics:

```python
from ignite.contrib.handlers.tensorboard_logger import *

tb_logger = TensorboardLogger(log_dir="tensorboard_logs")

# Log training loss at each iteration
tb_logger.attach(
    trainer,
    log_handler=OutputHandler(
        tag="training",
        output_transform=lambda loss: {"loss": loss}
    ),
    event_name=Events.ITERATION_COMPLETED
)

# Log validation metrics after each epoch
tb_logger.attach(
    evaluator,
    log_handler=OutputHandler(
        tag="validation",
        metric_names=["loss", "accuracy"],
        another_engine=trainer
    ),
    event_name=Events.EPOCH_COMPLETED
)

# Close the TensorBoard logger when training completes
tb_logger.attach(
    trainer,
    log_handler=lambda _: tb_logger.close(),
    event_name=Events.COMPLETED
)
```

## Real-World Example: Transfer Learning

Let's implement a more complete example using transfer learning on a real dataset:

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator
from ignite.metrics import Accuracy, Loss
from ignite.handlers import ModelCheckpoint, EarlyStopping
from ignite.contrib.handlers import ProgressBar

# Data augmentation and normalization
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

# Example: flower classification dataset paths (replace with your dataset)
data_dir = './flower_data'
image_datasets = {x: datasets.ImageFolder(f'{data_dir}/{x}', data_transforms[x])
                  for x in ['train', 'val']}

dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)
               for x in ['train', 'val']}

# Model setup - use a pre-trained ResNet
model = models.resnet18(pretrained=True)
num_classes = 5  # Example for 5 types of flowers

# Replace the last fully connected layer
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)

# Move to GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# Setup training
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# Create Ignite engines
trainer = create_supervised_trainer(model, optimizer, criterion, device=device)
evaluator = create_supervised_evaluator(
    model,
    metrics={'accuracy': Accuracy(), 'loss': Loss(criterion)},
    device=device
)

# Add progress bar
pbar = ProgressBar()
pbar.attach(trainer, output_transform=lambda x: {'loss': x})

# Add learning rate scheduler
@trainer.on(Events.EPOCH_COMPLETED)
def update_lr_scheduler(engine):
    scheduler.step()

# Log training and validation metrics
@trainer.on(Events.EPOCH_COMPLETED)
def log_training_results(engine):
    evaluator.run(dataloaders['train'])
    metrics = evaluator.state.metrics
    print(f"Training Results - Epoch: {engine.state.epoch} "
          f"Avg accuracy: {metrics['accuracy']:.3f} "
          f"Avg loss: {metrics['loss']:.3f}")
    
@trainer.on(Events.EPOCH_COMPLETED)
def log_validation_results(engine):
    evaluator.run(dataloaders['val'])
    metrics = evaluator.state.metrics
    print(f"Validation Results - Epoch: {engine.state.epoch} "
          f"Avg accuracy: {metrics['accuracy']:.3f} "
          f"Avg loss: {metrics['loss']:.3f}")

# Model checkpointing - save best model
checkpoint_handler = ModelCheckpoint(
    'saved_models', 
    'best', 
    n_saved=3, 
    filename_prefix='resnet18',
    score_function=lambda engine: engine.state.metrics['accuracy'],
    score_name="accuracy",
    require_empty=False
)
evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, {'model': model})

# Early stopping
early_stopping = EarlyStopping(
    patience=5, 
    score_function=lambda engine: engine.state.metrics['accuracy'],
    trainer=trainer
)
evaluator.add_event_handler(Events.COMPLETED, early_stopping)

# Run the training
trainer.run(dataloaders['train'], max_epochs=25)
```

This example demonstrates a more complete training pipeline with:
- Transfer learning using a pre-trained ResNet
- Training/validation data loading and transformation
- Learning rate scheduling
- Progress bar visualization 
- Model checkpointing based on best validation accuracy
- Early stopping to prevent overfitting

## Summary

PyTorch Ignite provides a clean, modular framework for training neural networks. By using Ignite, you can:

1. Organize your training and evaluation code more effectively
2. Reduce boilerplate code and focus on model architecture
3. Track performance metrics with minimal effort
4. Implement advanced features like early stopping and checkpointing easily
5. Visualize results with integrations like TensorBoard

Ignite follows a paradigm that encourages modularity and extensibility without limiting your control over the training process. It's an excellent tool for both beginners and experienced PyTorch users who want to make their code more maintainable and structured.

## Additional Resources

- [Official PyTorch Ignite documentation](https://pytorch.org/ignite/)
- [GitHub repository](https://github.com/pytorch/ignite)
- [Examples and tutorials](https://github.com/pytorch/ignite/tree/master/examples)

## Exercises

1. Modify the MNIST example to use a different neural network architecture and compare the results.
2. Implement a training pipeline for a text classification task using PyTorch Ignite.
3. Create a custom metric and attach it to an evaluator engine.
4. Extend the transfer learning example to include more advanced data augmentation techniques.
5. Implement a learning rate finder using PyTorch Ignite's event system to determine the optimal learning rate.

By working through these exercises, you'll gain a deeper understanding of how PyTorch Ignite can help streamline your deep learning workflows while maintaining flexibility and control.