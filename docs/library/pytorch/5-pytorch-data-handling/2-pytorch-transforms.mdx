---
title: PyTorch Transforms
description: Learn how to preprocess and augment data using PyTorch Transforms for machine learning and deep learning models

---

# PyTorch Transforms

## Introduction

In machine learning and deep learning, data preprocessing is a crucial step before feeding data into models. PyTorch provides a powerful tool called **Transforms** that helps standardize, normalize, and augment your data. Transforms are particularly useful for image processing tasks, though they can be extended to other data types as well.

In this tutorial, we'll explore PyTorch Transforms, understand how they work, and learn how to use them effectively to prepare your data for training deep learning models.

## What are PyTorch Transforms?

PyTorch Transforms are a set of common image transformations available in the `torchvision.transforms` module. These transforms can be used to:

- Convert data between different formats (e.g., PIL Images to tensors)
- Normalize data to have specific mean and standard deviation
- Resize or crop images to consistent dimensions
- Apply data augmentation techniques like rotation, flipping, or color jittering
- Chain multiple transformations together

## Basic Usage of Transforms

Let's start with importing the necessary modules and understanding the basic usage:

```python
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

# Load a sample image
img = Image.open('sample_image.jpg')

# Define a simple transform
transform = transforms.ToTensor()

# Apply the transform
img_tensor = transform(img)

print(f"Type: {type(img_tensor)}")
print(f"Shape: {img_tensor.shape}")
```

Output:
```
Type: <class 'torch.Tensor'>
Shape: torch.Size([3, 224, 224])  # Assuming the image is 224×224 pixels with 3 channels (RGB)
```

## Common Transforms

### Converting Between Data Types

#### `ToTensor`

Converts a PIL Image or NumPy array to a PyTorch tensor and scales the values to [0, 1].

```python
to_tensor = transforms.ToTensor()
img_tensor = to_tensor(img)
```

#### `ToPILImage`

Converts a PyTorch tensor or NumPy array back to a PIL Image.

```python
to_pil = transforms.ToPILImage()
img_pil = to_pil(img_tensor)
```

### Resizing and Cropping

#### `Resize`

Resizes an image to a given size.

```python
resize = transforms.Resize((224, 224))
resized_img = resize(img)
```

#### `CenterCrop`

Crops the image at the center to a given size.

```python
center_crop = transforms.CenterCrop((200, 200))
cropped_img = center_crop(img)
```

#### `RandomCrop`

Crops the image at a random location.

```python
random_crop = transforms.RandomCrop((180, 180))
randomly_cropped_img = random_crop(img)
```

### Normalization

#### `Normalize`

Normalizes a tensor image with a given mean and standard deviation.

```python
# Standard normalization for ImageNet pre-trained models
normalize = transforms.Normalize(
    mean=[0.485, 0.456, 0.406],  # RGB mean
    std=[0.229, 0.224, 0.225]    # RGB standard deviation
)

normalized_img_tensor = normalize(img_tensor)
```

### Data Augmentation Transforms

#### `RandomHorizontalFlip`

Randomly flips the image horizontally with a given probability.

```python
random_flip = transforms.RandomHorizontalFlip(p=0.5)
flipped_img = random_flip(img)
```

#### `RandomRotation`

Rotates the image by a random angle.

```python
random_rotate = transforms.RandomRotation(degrees=15)  # ±15 degrees
rotated_img = random_rotate(img)
```

#### `ColorJitter`

Randomly changes the brightness, contrast, saturation, and hue of an image.

```python
color_jitter = transforms.ColorJitter(
    brightness=0.2,
    contrast=0.2,
    saturation=0.2,
    hue=0.1
)
jittered_img = color_jitter(img)
```

## Combining Transforms

One of the most powerful features of PyTorch transforms is the ability to chain them together using `transforms.Compose`.

```python
transform_pipeline = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# Apply all transforms at once
processed_img = transform_pipeline(img)
```

## Practical Example: Image Classification Dataset

Let's see how transforms are used in a real-world scenario with a dataset for image classification:

```python
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# Define different transforms for training and validation sets
train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),  # No random crop for validation
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load CIFAR-10 dataset with the transforms
train_dataset = torchvision.datasets.CIFAR10(
    root='./data', 
    train=True,
    download=True, 
    transform=train_transforms
)

val_dataset = torchvision.datasets.CIFAR10(
    root='./data', 
    train=False,
    download=True, 
    transform=val_transforms
)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Visualizing a sample from the transformed dataset
def visualize_sample(dataset):
    img, label = dataset[0]
    img = transforms.ToPILImage()(img)
    plt.imshow(img)
    plt.title(f"Class: {dataset.classes[label]}")
    plt.axis('off')
    plt.show()

visualize_sample(train_dataset)
```

## Custom Transforms

Sometimes you might need transformations that aren't available in PyTorch's built-in options. In such cases, you can create custom transforms by inheriting from `torch.nn.Module` or by creating a callable class:

```python
class GaussianNoise:
    def __init__(self, mean=0.0, std=1.0):
        self.mean = mean
        self.std = std
        
    def __call__(self, tensor):
        return tensor + torch.randn_like(tensor) * self.std + self.mean
    
    def __repr__(self):
        return f"{self.__class__.__name__}(mean={self.mean}, std={self.std})"

# Use custom transform
transform_with_noise = transforms.Compose([
    transforms.ToTensor(),
    GaussianNoise(mean=0.0, std=0.1)
])

noisy_img_tensor = transform_with_noise(img)
```

## Transforms for Non-Image Data

While transforms are most commonly used for images, they can be adapted for other data types as well.

### Text Data

For text data, you might create transforms that tokenize, pad, or augment text:

```python
class TextToIndices:
    def __init__(self, vocab):
        self.vocab = vocab
        
    def __call__(self, text):
        return torch.tensor([self.vocab.get(word, 0) for word in text.split()])

# Example usage
vocab = {"hello": 1, "world": 2}
text_transform = TextToIndices(vocab)
indices = text_transform("hello world")
print(indices)  # tensor([1, 2])
```

### Time Series Data

For time series data, you might create transforms that normalize, window, or augment sequences:

```python
class TimeSeriesNormalize:
    def __call__(self, series):
        return (series - series.mean()) / series.std()

# Example with a time series tensor
time_series = torch.randn(100)
norm_transform = TimeSeriesNormalize()
normalized_series = norm_transform(time_series)
```

## Best Practices for Working with Transforms

1. **Different Transforms for Training and Validation**: Use data augmentation only for training data, not validation or test data.

2. **Normalize According to Dataset Statistics**: Calculate the mean and standard deviation of your specific dataset for best results.

3. **Chain Transforms Efficiently**: Order your transforms logically (e.g., resize before crop, and apply ToTensor before normalization).

4. **Test Your Transforms**: Visualize samples after applying transforms to ensure they're producing the expected output.

5. **Document Your Transforms**: When sharing models and results, always document the exact transforms used.

## Summary

PyTorch Transforms provide a powerful and flexible way to preprocess and augment data for deep learning models. We've covered the basics of transforms, common transformations, how to combine them, and how to apply them in real-world scenarios.

Key takeaways:
- Transforms can convert data between types, resize images, normalize data, and apply augmentations
- Multiple transforms can be chained with `transforms.Compose`
- Different transforms should be used for training versus validation data
- Custom transforms can be created for specialized needs
- While most commonly used for images, transforms can be adapted for other data types

## Additional Resources

- [PyTorch Documentation on Transforms](https://pytorch.org/vision/stable/transforms.html)
- [Data Augmentation Best Practices](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)
- [Transfer Learning and Transforms](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)

## Exercises

1. Create a transform pipeline that includes at least 5 different transforms for an image classification task.
2. Implement a custom transform that adds random text overlay to images.
3. Write a function that displays a grid of images showing the effect of each transform in your pipeline.
4. Calculate the mean and standard deviation of a dataset (like CIFAR-10) and create a custom normalization transform.
5. Create a transform pipeline for a non-image dataset and demonstrate its effects.

By mastering PyTorch Transforms, you'll be well-equipped to prepare optimal input data for your deep learning models, which can significantly improve their performance and generalization capabilities.