---
title: PyTorch autograd.detect_anomaly
description: Learn how to use PyTorch's autograd.detect_anomaly to identify and debug issues in your neural network computations

---

# PyTorch autograd.detect_anomaly

## Introduction

When developing neural networks with PyTorch, you may sometimes encounter mysterious errors during the backward pass (backpropagation) that are difficult to trace. These issues might include:

- Gradients that contain `NaN` or `Inf` values
- Unexpected computational graphs
- Various backpropagation failures

PyTorch provides a powerful debugging tool called `autograd.detect_anomaly()` that helps identify the source of these problems. This feature enhances error messages and enables you to track down where numerical issues originate in your computation graph.

## What is autograd.detect_anomaly?

`autograd.detect_anomaly()` is a context manager (or decorator) that enables anomaly detection for autograd computations. When enabled:

1. PyTorch tracks the forward pass with additional metadata
2. It performs checks during the backward pass
3. If an error occurs, it provides more informative error messages with traceback to the specific operation that caused the issue

This tool is invaluable when you have complex computations that might produce `NaN` or `Inf` values.

## How to Use autograd.detect_anomaly

### Basic Usage as a Context Manager

You can use `detect_anomaly()` as a context manager to wrap the portion of your code that might have numerical issues:

```python
import torch

# Enable anomaly detection
with torch.autograd.detect_anomaly():
    x = torch.tensor([1.0], requires_grad=True)
    y = x ** 2
    z = y * torch.tensor([float('nan')])
    z.backward()
```

When you run this code, PyTorch will produce a more detailed error message:

```
RuntimeError: Function 'MulBackward0' returned nan values in its 0th output.
The forward pass of the function was recorded and an error occurred in the backward pass.
...
```

The error will include a traceback that points to the exact line in your code that introduced the `NaN` value.

### Using as a Function Decorator

You can also use `detect_anomaly()` as a decorator for functions containing autograd operations:

```python
import torch

@torch.autograd.detect_anomaly()
def problematic_function():
    x = torch.tensor([1.0], requires_grad=True)
    y = x ** 2
    z = y / torch.tensor([0.0])  # Division by zero
    z.backward()
    
# This will raise an error with detailed information
problematic_function()
```

## Real-World Example: Debugging a Neural Network Training Loop

Let's look at a more practical example where `detect_anomaly()` helps find issues in a neural network:

```python
import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple neural network with potential numerical issues
class UnstableNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear1 = nn.Linear(10, 10)
        self.linear2 = nn.Linear(10, 1)
        
    def forward(self, x):
        x = torch.exp(self.linear1(x))  # Potential for overflow
        x = self.linear2(x)
        return x

# Training function with detect_anomaly enabled
def train_model(model, inputs, targets):
    optimizer = optim.SGD(model.parameters(), lr=1.0)  # Intentionally high learning rate
    criterion = nn.MSELoss()
    
    with torch.autograd.detect_anomaly():
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        
        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        return loss.item()

# Create synthetic data with extreme values
inputs = torch.randn(32, 10) * 10  # Large input values
targets = torch.randn(32, 1)

# Initialize model and start training
model = UnstableNetwork()
try:
    loss = train_model(model, inputs, targets)
    print(f"Training loss: {loss}")
except RuntimeError as e:
    print(f"Detected numerical issue: {e}")
```

This example will likely produce an error due to numerical instability from the exponential function combined with large input values and a high learning rate. The `detect_anomaly()` context manager will help identify exactly where the problem occurs.

## Understanding the Output

When an anomaly is detected, PyTorch provides information that helps you debug the issue:

1. **Function name**: Shows which autograd function encountered the problem
2. **Type of anomaly**: Indicates whether it was a `NaN`, `Inf`, or other issue
3. **Traceback**: Points to the line in your code where the problematic operation was created
4. **Additional context**: May include values of tensors involved in the computation

## Best Practices

### When to Use detect_anomaly

- During development and debugging phases
- When you encounter unexplained errors in the backward pass
- When your model is producing `NaN` or `Inf` values
- When loss becomes unstable without clear reason

### When Not to Use detect_anomaly

- In production code as it adds computational overhead
- During normal training after your model is stable
- For large-scale training where performance is critical

### Performance Considerations

Enabling anomaly detection introduces additional overhead during both forward and backward passes:

```python
import time
import torch

def benchmark_with_and_without_detection():
    x = torch.randn(1000, 1000, requires_grad=True)
    
    # Without detection
    start = time.time()
    y = x ** 2
    y.sum().backward()
    without_detection = time.time() - start
    
    # Reset gradients
    x.grad = None
    
    # With detection
    start = time.time()
    with torch.autograd.detect_anomaly():
        y = x ** 2
        y.sum().backward()
    with_detection = time.time() - start
    
    print(f"Without detection: {without_detection:.4f} seconds")
    print(f"With detection: {with_detection:.4f} seconds")
    print(f"Overhead: {(with_detection/without_detection - 1)*100:.2f}%")

benchmark_with_and_without_detection()
```

This might output something like:

```
Without detection: 0.0123 seconds
With detection: 0.0245 seconds
Overhead: 99.19%
```

## Common Issues and Solutions

### 1. NaN Gradients

```python
with torch.autograd.detect_anomaly():
    # Problem: Division by zero
    x = torch.tensor([1.0], requires_grad=True)
    y = 1 / (x - 1)  # Division by zero when x=1
    y.backward()
```

**Solution**: Add checks or use functions with better numerical stability:

```python
x = torch.tensor([1.0], requires_grad=True)
# Add a small epsilon to avoid division by zero
y = 1 / (x - 1 + 1e-6)
```

### 2. Exploding Gradients

```python
with torch.autograd.detect_anomaly():
    # Problem: Exponential of large values
    x = torch.tensor([100.0], requires_grad=True)
    y = torch.exp(x)  # Very large value
    z = y.sum()
    z.backward()
```

**Solution**: Use gradient clipping and proper initialization:

```python
# For network parameters
nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# For manual operations
x = torch.tensor([100.0], requires_grad=True)
# Use a numerically stable approach
y = torch.clamp(x, max=20.0)  # Limit the input value
z = torch.exp(y)
```

## Summary

PyTorch's `autograd.detect_anomaly()` is an essential debugging tool that helps identify numerical issues during backpropagation. By tracking the computational graph and providing detailed error messages, it enables developers to quickly find and fix problems in their neural network implementations.

Key points to remember:

- Use it as a context manager or decorator during debugging
- It helps identify the origin of NaN/Inf values
- Provides detailed tracebacks to the source of problems
- Has performance overhead, so use mainly during development
- Combine with other debugging practices for effective problem-solving

## Additional Resources

- [PyTorch Autograd Documentation](https://pytorch.org/docs/stable/autograd.html)
- [PyTorch Forum - Debugging Tips](https://discuss.pytorch.org/)
- [Guide to Numerical Stability in Deep Learning](https://pytorch.org/tutorials/)

## Exercises

1. Create a simple neural network that deliberately produces NaN gradients and use `detect_anomaly()` to identify the issue.

2. Investigate how different activation functions (ReLU, sigmoid, tanh) behave with extreme input values when monitored with `detect_anomaly()`.

3. Compare the performance impact of `detect_anomaly()` on models of different sizes.

4. Debug a common numerical stability issue like vanishing gradients using `detect_anomaly()` combined with gradient norm tracking.