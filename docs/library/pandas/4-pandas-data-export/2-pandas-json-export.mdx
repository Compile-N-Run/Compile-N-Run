---
title: "Pandas JSON Export"
description: "Learn how to export Pandas DataFrames to JSON format, customize the output, and use different orientations for effective data interchange."

---

# Pandas JSON Export

JSON (JavaScript Object Notation) is a lightweight data interchange format that's easy for humans to read and write and easy for machines to parse and generate. Exporting Pandas DataFrames to JSON format is an essential skill when working with web applications, APIs, or any system that requires data in a standardized format.

## Introduction to JSON in Pandas

Pandas provides the `to_json()` method to export DataFrame or Series objects to JSON format. This method is flexible, offering various parameters to customize how your data is converted.

Let's explore how to use this functionality effectively to transform your Pandas data into JSON.

## Basic JSON Export

To get started, let's create a simple DataFrame and export it to JSON:

```python
import pandas as pd

# Create a sample DataFrame
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['New York', 'San Francisco', 'Los Angeles']
})

print("Original DataFrame:")
print(df)

# Export DataFrame to JSON
json_data = df.to_json()

print("\nJSON output:")
print(json_data)
```

Output:
```
Original DataFrame:
      name  age           city
0    Alice   25       New York
1      Bob   30  San Francisco
2  Charlie   35    Los Angeles

JSON output:
{"name":{"0":"Alice","1":"Bob","2":"Charlie"},"age":{"0":25,"1":30,"2":35},"city":{"0":"New York","1":"San Francisco","2":"Los Angeles"}}
```

By default, the `to_json()` method returns a JSON string with columns as the primary keys. Notice that the default output is not very human-readable.

## Customizing JSON Output

### Pretty Print JSON

For better readability, you can format the JSON output using the `indent` parameter:

```python
# Export with pretty printing
json_pretty = df.to_json(indent=4)
print("Pretty-printed JSON:")
print(json_pretty)
```

Output:
```
Pretty-printed JSON:
{
    "name":{
        "0":"Alice",
        "1":"Bob",
        "2":"Charlie"
    },
    "age":{
        "0":25,
        "1":30,
        "2":35
    },
    "city":{
        "0":"New York",
        "1":"San Francisco",
        "2":"Los Angeles"
    }
}
```

### Changing JSON Orientation

Pandas offers several orientation options for JSON output. The default is 'columns', but you can change this with the `orient` parameter:

```python
# Different orientations
orientations = ['split', 'records', 'index', 'columns', 'values', 'table']

for orient in orientations:
    print(f"\nOrientation: {orient}")
    print(df.to_json(orient=orient, indent=2))
```

Let's examine a few key orientations:

#### Records Orientation

The 'records' orientation is particularly useful for API responses and data interchange:

```python
# Records orientation - list of dictionaries
json_records = df.to_json(orient='records', indent=2)
print("\nRecords orientation:")
print(json_records)
```

Output:
```
Records orientation:
[
  {
    "name":"Alice",
    "age":25,
    "city":"New York"
  },
  {
    "name":"Bob",
    "age":30,
    "city":"San Francisco"
  },
  {
    "name":"Charlie",
    "age":35,
    "city":"Los Angeles"
  }
]
```

#### Split Orientation

The 'split' orientation separates column names, index, and data:

```python
# Split orientation
json_split = df.to_json(orient='split', indent=2)
print("\nSplit orientation:")
print(json_split)
```

Output:
```
Split orientation:
{
  "columns":[
    "name",
    "age",
    "city"
  ],
  "index":[
    0,
    1,
    2
  ],
  "data":[
    [
      "Alice",
      25,
      "New York"
    ],
    [
      "Bob",
      30,
      "San Francisco"
    ],
    [
      "Charlie",
      35,
      "Los Angeles"
    ]
  ]
}
```

## Saving JSON to a File

To save the JSON data directly to a file:

```python
# Save to a file
df.to_json('data.json', orient='records', indent=2)
print("Saved JSON data to 'data.json'")

# Read it back
with open('data.json', 'r') as f:
    file_content = f.read()
    print("\nContent of the saved file:")
    print(file_content)
```

## Date and Time Handling

When working with date and time data, you can use the `date_format` parameter:

```python
# Create a DataFrame with dates
date_df = pd.DataFrame({
    'event': ['Conference', 'Meeting', 'Workshop'],
    'date': pd.to_datetime(['2023-01-15', '2023-02-20', '2023-03-25'])
})

print("DataFrame with dates:")
print(date_df)

# Export with different date formats
print("\nISO format:")
print(date_df.to_json(date_format='iso'))

print("\nEpoch seconds:")
print(date_df.to_json(date_format='epoch'))
```

Output:
```
DataFrame with dates:
        event       date
0  Conference 2023-01-15
1     Meeting 2023-02-20
2    Workshop 2023-03-25

ISO format:
{"event":{"0":"Conference","1":"Meeting","2":"Workshop"},"date":{"0":"2023-01-15T00:00:00.000Z","1":"2023-02-20T00:00:00.000Z","2":"2023-03-25T00:00:00.000Z"}}

Epoch seconds:
{"event":{"0":"Conference","1":"Meeting","2":"Workshop"},"date":{"0":1673740800000,"1":1676851200000,"2":1679702400000}}
```

## Handling Missing Values

Pandas provides options for handling missing values in JSON output:

```python
# DataFrame with missing values
missing_df = pd.DataFrame({
    'name': ['Alice', 'Bob', None],
    'score': [85, None, 92]
})

print("DataFrame with missing values:")
print(missing_df)

# Default behavior
print("\nDefault JSON (null values):")
print(missing_df.to_json())
```

Output:
```
DataFrame with missing values:
    name  score
0  Alice   85.0
1    Bob    NaN
2   None   92.0

Default JSON (null values):
{"name":{"0":"Alice","1":"Bob","2":null},"score":{"0":85.0,"1":null,"2":92.0}}
```

## Real-World Application: Creating a Web API Response

Let's simulate a real-world scenario where you might use Pandas JSON export to create a response for a web API:

```python
import pandas as pd
from datetime import datetime

# Load sales data
sales_data = pd.DataFrame({
    'product_id': [101, 102, 103, 104, 105],
    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],
    'quantity_sold': [15, 25, 10, 30, 8],
    'price': [1200.50, 699.99, 350.50, 149.99, 249.99],
    'sale_date': pd.to_datetime([
        '2023-05-10', '2023-05-11', '2023-05-12', 
        '2023-05-13', '2023-05-14'
    ])
})

# Calculate total sales
sales_data['total_sale'] = sales_data['quantity_sold'] * sales_data['price']

print("Sales data:")
print(sales_data)

# Generate API response
def generate_sales_api_response(df):
    # Calculate summary statistics
    summary = {
        'total_revenue': float(df['total_sale'].sum()),
        'total_products_sold': int(df['quantity_sold'].sum()),
        'average_price': float(df['price'].mean()),
        'response_timestamp': datetime.now().isoformat()
    }
    
    # Prepare response data
    response = {
        'status': 'success',
        'summary': summary,
        'data': df.to_dict(orient='records')
    }
    
    # Convert to JSON
    import json
    return json.dumps(response, indent=2, default=str)

api_response = generate_sales_api_response(sales_data)
print("\nAPI Response JSON:")
print(api_response)
```

This example demonstrates how you might combine Pandas JSON export with additional processing to create a structured API response.

## Performance Considerations

For very large DataFrames, the JSON export process can be memory-intensive. Consider these tips:

1. Use `lines=True` for line-delimited JSON to process large files in chunks
2. Consider using compression for large files with `compression='gzip'`
3. Choose appropriate orientations for your use case (e.g., 'records' is typically more concise than 'columns')

```python
# Example with lines=True for large datasets
large_df = pd.DataFrame({
    'id': range(1000),
    'value': range(1000)
})

# Export as line-delimited JSON
large_df.to_json('large_data.json', orient='records', lines=True)
print("Saved line-delimited JSON. First few lines:")

# Show the first few lines
with open('large_data.json', 'r') as f:
    for _ in range(3):
        print(f.readline().strip())
```

## Summary

Exporting Pandas DataFrames to JSON format provides a flexible way to share data between different systems. In this tutorial, we've covered:

- Basic JSON export using `to_json()`
- Customizing JSON output with parameters like `indent` and `orient`
- Working with different JSON orientations
- Saving JSON data to files
- Handling dates and missing values
- Real-world application in a web API context
- Performance considerations for large datasets

The ability to customize JSON output makes Pandas an excellent tool for data interchange in web applications, APIs, and other systems that consume JSON data.

## Additional Resources and Exercises

### Further Reading
- [Pandas Official Documentation on to_json](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html)
- [JSON Format Specification](https://www.json.org/)

### Exercises

1. **Basic Export**: Create a DataFrame with student information (name, grade, subjects) and export it to JSON in 'records' orientation.

2. **File Operations**: Export a DataFrame to JSON and then read it back using `pd.read_json()`. Verify that the data remains intact.

3. **Advanced Formatting**: Create a nested data structure with a DataFrame containing customer information and another with their orders. Export it as a hierarchical JSON document.

4. **Performance Challenge**: Generate a large DataFrame (100,000+ rows) and experiment with different orientations and the `lines=True` parameter. Compare the file sizes and export times.

5. **Web Integration**: Create a simple Flask or FastAPI endpoint that returns DataFrame data as JSON with appropriate formatting.

By mastering Pandas JSON export, you'll be well-equipped to integrate your data processing pipelines with web services, APIs, and other systems that rely on JSON for data interchange.