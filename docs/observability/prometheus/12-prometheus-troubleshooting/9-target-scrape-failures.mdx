---
title: Target Scrape Failures
description: Learn how to identify, debug, and resolve target scrape failures in Prometheus monitoring

---

# Target Scrape Failures

## Introduction

In Prometheus, a monitoring system that collects metrics from configured targets, one of the most common issues you might encounter is **target scrape failures**. These occur when Prometheus cannot successfully collect metrics from a specified target. Understanding why these failures happen and how to resolve them is crucial for maintaining a reliable monitoring system.

A scrape failure can happen for various reasons - network issues, misconfiguration, authentication problems, or target service unavailability. This guide will help you identify, debug, and fix scrape failures in your Prometheus setup.

## Understanding Target Scrape Failures

### What is a Scrape?

Before diving into failures, let's understand what a scrape operation is:

```mermaid
graph LR
    A[Prometheus Server] -->|HTTP request| B[Target]
    B -->|Metrics response| A
    style A fill:#f9d77e,stroke:#333,stroke-width:2px
    style B fill:#a3c9ff,stroke:#333,stroke-width:2px
```

Prometheus works on a pull model where it periodically sends HTTP requests (typically to `/metrics` endpoints) to collect data from targets. This data collection process is called a "scrape."

### What Constitutes a Scrape Failure?

A scrape failure occurs when:

1. Prometheus cannot reach the target
2. The target returns a non-2xx HTTP status code
3. The connection times out
4. The response format is invalid
5. Authentication fails

## Identifying Scrape Failures

### Using the Prometheus UI

The simplest way to identify scrape failures is through the Prometheus UI:

1. Navigate to your Prometheus web interface (typically at `http://your-prometheus-server:9090`)
2. Go to the "Status" dropdown menu
3. Select "Targets"
4. Look for targets with state "DOWN" or any error messages

![Target status page showing failures]

### Using Prometheus Metrics

Prometheus exposes metrics about its own scraping performance:

```
# HELP up Whether the target is up (1) or not (0)
# TYPE up gauge
up{job="<job_name>", instance="<instance>"} 0
```

You can query failed targets with:

```promql
up == 0
```

### Common Error Messages

Here are some typical error messages and what they indicate:

- `context deadline exceeded`: Timeout connecting to the target
- `connection refused`: Target service is not running or not accepting connections
- `401 Unauthorized`: Authentication issue
- `404 Not Found`: Incorrect endpoint path
- `500 Internal Server Error`: Target is experiencing issues

## Troubleshooting Scrape Failures

### 1. Network Connectivity Issues

**Symptoms**: `context deadline exceeded`, `connection refused`, or `dial tcp: i/o timeout`

**Debugging Steps**:

```bash
# Check if you can reach the target from the Prometheus server
curl -v http://target-host:port/metrics

# Test using telnet
telnet target-host port

# Check for firewall rules
sudo iptables -L
```

**Resolution**:
- Ensure network connectivity between Prometheus and target
- Verify firewall rules allow traffic
- Check if the target service is running

### 2. Configuration Issues

**Symptoms**: Wrong endpoint, incorrect port, or invalid parameters

**Debugging**:

Check your Prometheus configuration file (`prometheus.yml`):

```yaml
scrape_configs:
  - job_name: 'example-job'
    scrape_interval: 15s
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets: ['localhost:9090', 'localhost:9100']
```

**Resolution**:
- Verify the correct port, metrics path, and scheme
- Ensure target IP/hostname is correct
- Apply configuration changes and reload Prometheus:

```bash
curl -X POST http://prometheus-host:9090/-/reload
```

### 3. Authentication Problems

**Symptoms**: `401 Unauthorized` or `403 Forbidden`

**Resolution**:
- Configure the correct authentication in your scrape config:

```yaml
scrape_configs:
  - job_name: 'secure-endpoint'
    scheme: https
    basic_auth:
      username: 'prometheus'
      password: 'password'
    static_configs:
      - targets: ['secure-host:8443']
```

### 4. TLS/SSL Issues

**Symptoms**: `x509: certificate signed by unknown authority`

**Resolution**:
- Configure TLS settings correctly:

```yaml
scrape_configs:
  - job_name: 'https-endpoint'
    scheme: https
    tls_config:
      cert_file: /path/to/certificate.cert
      key_file: /path/to/key.key
      insecure_skip_verify: false  # Set to true to skip verification (not recommended for production)
    static_configs:
      - targets: ['secure-host:8443']
```

### 5. Target Service Issues

**Symptoms**: `500 Internal Server Error` or metrics endpoint not working

**Debugging**:
- Check the logs of the target service
- Manually query the metrics endpoint:

```bash
curl -v http://target-host:port/metrics
```

**Resolution**:
- Restart the target service if needed
- Fix any issues with the target's metrics exporter

## Real-World Example: Troubleshooting Node Exporter

Let's walk through a complete example of troubleshooting a scrape failure with Node Exporter:

### Scenario
You've configured Prometheus to scrape a Node Exporter instance, but it's showing as "DOWN" in the targets page.

### Step 1: Check the error message
In the Prometheus UI under Status > Targets, you see:
```
Error: connection refused
```

### Step 2: Verify the Node Exporter is running
```bash
# Check if process is running
ps aux | grep node_exporter

# If not running, start it
node_exporter
```

### Step 3: Verify connectivity
```bash
# Test from Prometheus server
curl http://node-exporter-host:9100/metrics
```

### Step 4: Check your Prometheus configuration
```yaml
scrape_configs:
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter-host:9100']
```

### Step 5: Solve the issue
In this case, the Node Exporter wasn't running. After starting it:

```bash
# Start Node Exporter with proper permissions
sudo systemctl start node_exporter

# Or run manually
./node_exporter
```

After restarting the service, the target shows as "UP" in Prometheus.

## Advanced Troubleshooting: Custom Relabel Configurations

Sometimes targets fail because of relabeling issues. Check your relabel configurations:

```yaml
scrape_configs:
  - job_name: 'relabeled-job'
    static_configs:
      - targets: ['host:port']
    relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):(.*)'
        target_label: instance
        replacement: '$1'
```

## Summary

Target scrape failures are a common issue in Prometheus deployments. By systematically checking for network, configuration, authentication, and target service issues, you can quickly identify and resolve these problems.

Remember these key points:
- Use the Prometheus UI to quickly identify failed targets
- Query `up == 0` to get a list of failed targets
- Check connectivity from the Prometheus server to the target
- Verify your configuration for correct endpoints and parameters
- Examine target service logs for any issues
- Restart Prometheus after configuration changes with `prometheus --config.file=prometheus.yml`

## Additional Resources

- [Prometheus Documentation on Scraping](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)
- [Debugging Prometheus Metrics Exposition](https://prometheus.io/docs/guides/basic-auth/)
- [Understanding Prometheus Relabeling](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config)

## Exercises

1. Deliberately misconfigure a target in your Prometheus setup and practice troubleshooting it.
2. Set up a secure endpoint requiring TLS and basic authentication, then configure Prometheus to scrape it.
3. Create a dashboard in Grafana that shows all your failed targets based on the `up` metric.
4. Use the Prometheus API to fetch the status of all targets programmatically.