---
title: Troubleshooting Performance Issues
description: Learn how to identify, diagnose and resolve common performance issues in Grafana dashboards and queries

---

# Troubleshooting Performance Issues

## Introduction

Performance issues in Grafana can significantly impact user experience and the effectiveness of your monitoring solution. Whether you're experiencing slow dashboard loading times, query timeouts, or high resource utilization, understanding how to troubleshoot these problems is essential for maintaining a responsive monitoring system.

This guide will walk you through the process of identifying, diagnosing, and resolving common performance issues in Grafana. We'll cover both dashboard-level optimizations and database query performance improvements, equipping you with the tools and knowledge to keep your Grafana instance running smoothly.

## Common Performance Issues in Grafana

Before diving into troubleshooting techniques, let's identify the most common performance issues you might encounter:

1. **Slow dashboard loading** - Dashboards taking several seconds or even minutes to load
2. **Query timeouts** - Queries failing to complete within the allocated time
3. **High resource usage** - Excessive CPU, memory, or network utilization
4. **Browser performance issues** - Sluggish UI interaction or browser crashes
5. **Panel rendering delays** - Individual panels taking too long to display data

## Diagnosing Performance Issues

### Using Grafana's Built-in Tools

Grafana provides several built-in tools to help diagnose performance issues:

#### 1. Query Inspector

The Query Inspector is one of your most valuable tools for troubleshooting performance issues related to data source queries.

To use the Query Inspector:

1. Open your dashboard
2. Click on the panel title
3. Select "Inspect" > "Query"

```
// Example of what you'll see in the Query Inspector
Query: SELECT mean("usage_idle") FROM "cpu" WHERE $timeFilter GROUP BY time($__interval) fill(null)
Data source: InfluxDB
Processing time: 2.43s
Number of data points: 1,258
```

The Query Inspector shows you:
- The actual query being sent to the data source
- How long the query took to execute
- The number of data points returned
- The raw data and query statistics

#### 2. Server-side Metrics

Grafana itself exposes internal metrics that you can scrape with Prometheus or other monitoring tools:

```bash
# Example Prometheus configuration to scrape Grafana metrics
- job_name: 'grafana'
  static_configs:
  - targets: ['grafana:3000']
  metrics_path: /metrics
```

Key metrics to monitor include:
- `grafana_http_request_duration_seconds` - HTTP request latencies
- `grafana_sql_datasource_query_total` - Total number of SQL queries
- `grafana_alerting_rule_evaluation_duration_seconds` - Alert rule evaluation duration

### Browser Performance Tools

Modern browsers come with powerful developer tools that can help diagnose client-side performance issues:

1. Open your browser's Developer Tools (F12 in most browsers)
2. Navigate to the "Performance" or "Network" tab
3. Record a session while loading and interacting with your dashboard

Look for:
- Long-running JavaScript operations
- Excessive network requests
- Large payload sizes
- Render blocking resources

## Troubleshooting Dashboard Performance

### Time Range Optimization

One of the most common causes of performance issues is querying too much data over a large time range.

```javascript
// Example of a query with time range variables
const timeRange = {
  from: 'now-24h',
  to: 'now'
};

// More efficient query with appropriate time range
const timeRange = {
  from: 'now-6h',
  to: 'now'
};
```

**Best practices:**
- Start with smaller time ranges and increase as needed
- Use appropriate time intervals for your data granularity
- Consider using relative time ranges (`now-1h`) instead of absolute time ranges

### Query Optimization

Inefficient queries are often the primary culprit behind performance issues:

```sql
-- Inefficient query that processes too much data
SELECT * FROM metrics WHERE time > now() - 24h

-- More efficient query with column selection and filtering
SELECT timestamp, value FROM metrics 
WHERE time > now() - 24h 
AND host = 'production-server'
LIMIT 1000
```

**Tips for optimizing queries:**
- Select only the columns you need
- Add appropriate WHERE clauses
- Use aggregation functions to reduce data points
- Apply LIMIT clauses where applicable
- Ensure indexes are present on frequently queried columns

### Panel Optimization

Individual panels can be optimized to improve performance:

1. **Reduce the number of queries per panel**:
   - Combine similar queries where possible
   - Use template variables efficiently

2. **Adjust refresh rates**:
   - Use auto-refresh rates appropriate to your data change frequency
   - Consider staggered refresh rates for different panels

3. **Panel visualization selection**:
   - Choose simpler visualizations for large datasets
   - Use time series panels instead of tables for time-based data
   - Consider using heatmaps for high-cardinality data

```javascript
// Example panel configuration with optimized refresh
{
  "panels": [
    {
      "title": "CPU Usage",
      "type": "timeseries",
      "datasource": "Prometheus",
      "maxDataPoints": 100,  // Limit data points
      "interval": "1m",      // Use 1-minute intervals
      // Other configuration...
    }
  ]
}
```

### Dashboard Structure

The way you structure your dashboards can significantly impact performance:

1. **Break up complex dashboards**:
   - Create multiple linked dashboards instead of one massive dashboard
   - Use dashboard variables to navigate between related dashboards

2. **Limit the number of panels**:
   - Keep panels under 20 per dashboard when possible
   - Use row collapsing to organize and hide panels that aren't always needed

3. **Use template variables wisely**:
   - Avoid having too many high-cardinality variables
   - Use regex or include/exclude filters to limit options

```javascript
// Example of template variables with filtering
{
  "templating": {
    "list": [
      {
        "name": "host",
        "query": "label_values(node_cpu_seconds_total, instance)",
        "regex": "/^prod-.*$/",  // Only show production hosts
        "includeAll": false
      }
    ]
  }
}
```

## Data Source Specific Optimizations

### Prometheus

Prometheus has specific performance considerations:

```promql
# Inefficient PromQL query
rate(http_requests_total[5m])

# More efficient query for high-cardinality metrics
sum by (service, endpoint) (rate(http_requests_total[5m]))
```

**Tips for Prometheus optimization:**
- Use recording rules for complex or frequently used queries
- Apply appropriate aggregations to reduce cardinality
- Use shorter time ranges in rate() and increase() functions
- Take advantage of subqueries for complex operations

### InfluxDB

For InfluxDB, consider these optimizations:

```sql
-- Inefficient InfluxDB query
SELECT * FROM "measurements" WHERE time > now() - 1h

-- More efficient query
SELECT mean("value") FROM "measurements" 
WHERE time > now() - 1h 
GROUP BY time(1m), "host"
```

**Tips for InfluxDB optimization:**
- Use GROUP BY time() clauses to downsample data
- Apply LIMIT and OFFSET for pagination
- Use tag-based filtering instead of field-based filtering
- Consider using Flux for more complex queries

### MySQL/PostgreSQL

When using SQL databases:

```sql
-- Inefficient SQL query
SELECT * FROM metrics ORDER BY timestamp DESC

-- More efficient query
SELECT timestamp, metric_value 
FROM metrics 
WHERE timestamp > NOW() - INTERVAL '1 day'
ORDER BY timestamp DESC 
LIMIT 1000
```

**Tips for SQL database optimization:**
- Use appropriate indexes on timestamp and filtering columns
- Apply LIMIT clauses to constrain result sets
- Use materialized views for complex aggregations
- Consider caching frequently accessed data

## Advanced Troubleshooting Techniques

### Profiling Grafana Server

For persistent issues, profiling the Grafana server can provide deeper insights:

```bash
# Start Grafana with profiling enabled
GF_DIAGNOSTICS_PROFILING_ENABLED=true grafana-server

# Access profiling data (available at /debug/pprof endpoint)
curl http://your-grafana-server:3000/debug/pprof/profile > profile.out
```

This generates CPU profiles that can be analyzed with tools like `pprof` to identify bottlenecks in the Grafana server code.

### Logging and Tracing

Enhance logging to capture more details about performance issues:

```bash
# Configure detailed logging in grafana.ini
[log]
level = debug
filters = rendering:debug alerting:debug

# Or set environment variables
GF_LOG_LEVEL=debug GF_LOG_FILTERS="rendering:debug alerting:debug" grafana-server
```

Review logs for:
- Slow query warnings
- Database connection issues
- Resource constraint messages
- Plugin errors

### Visualizing Performance Metrics

Create a dedicated dashboard to monitor Grafana's own performance:

```mermaid
graph LR
    A[Grafana Instance] -->|exposes| B[/metrics endpoint]
    B -->|scraped by| C[Prometheus]
    C -->|visualized in| D[Performance Dashboard]
    D -->|alerts on| E[Performance Issues]
```

Key metrics to include in your performance dashboard:
- Query latency by data source
- HTTP request duration
- Memory and CPU usage
- Database connection pool stats
- Alert processing time

## Common Performance Solutions

### Hardware and Infrastructure Scaling

When software optimizations are not enough:

1. **Increase resources for Grafana server**:
   - Add more CPU/memory
   - Use faster disks (SSD vs. HDD)
   - Scale vertically for better single-node performance

2. **Consider high availability setup**:
   - Use multiple Grafana instances behind a load balancer
   - Implement shared database for configuration storage
   - Use Redis for session caching

```bash
# Example Docker Compose setup for scaled Grafana
version: '3'
services:
  grafana-1:
    image: grafana/grafana
    volumes:
      - grafana-storage:/var/lib/grafana
    environment:
      - GF_DATABASE_HOST=postgres
      - GF_SESSION_PROVIDER=redis
      - GF_SESSION_PROVIDER_CONFIG=redis:6379
  
  grafana-2:
    image: grafana/grafana
    volumes:
      - grafana-storage:/var/lib/grafana
    environment:
      - GF_DATABASE_HOST=postgres
      - GF_SESSION_PROVIDER=redis
      - GF_SESSION_PROVIDER_CONFIG=redis:6379

  postgres:
    image: postgres
    # configuration...

  redis:
    image: redis
    # configuration...
```

### Caching Strategies

Implement appropriate caching:

1. **Query caching**:
   - Enable query caching in Grafana configuration
   - Set appropriate TTL (Time To Live) values

2. **Data source level caching**:
   - Configure caching in the data source (e.g., Prometheus recording rules)
   - Use time-series databases with efficient caching mechanisms

```ini
# Example Grafana configuration for query caching
[unified_alerting.query_caching]
enabled = true
default_timeout = 300s  # 5 minutes cache TTL
```

### Browser Optimizations

Improve client-side performance:

1. **Reduce browser load**:
   - Use efficient panel types
   - Limit the use of heavy visualizations like graph panels with many series

2. **Implement progressive loading**:
   - Use lazy loading for dashboard components
   - Start with smaller time ranges and allow users to expand as needed

## Performance Monitoring Best Practices

To proactively identify and resolve performance issues:

1. **Set up alerting on Grafana performance metrics**:
   - Alert on query latency exceeding thresholds
   - Monitor memory and CPU usage

2. **Regular performance testing**:
   - Test dashboard performance with different time ranges
   - Simulate multiple concurrent users

3. **Performance review process**:
   - Review dashboard performance before publishing
   - Implement a performance review checklist

```yaml
# Example Prometheus alert rule for Grafana performance
groups:
- name: GrafanaPerformanceAlerts
  rules:
  - alert: GrafanaSlowQueries
    expr: histogram_quantile(0.95, sum(rate(grafana_datasource_query_duration_seconds_bucket[5m])) by (datasource, le)) > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Slow queries detected"
      description: "95th percentile query time is over 10 seconds for data source {{ $labels.datasource }}"
```

## Summary

Troubleshooting performance issues in Grafana requires a systematic approach:

1. **Identify** the problem using Grafana's built-in tools and metrics
2. **Analyze** the bottlenecks in your dashboards, queries, or infrastructure
3. **Optimize** your dashboards, queries, and panel configurations
4. **Monitor** performance metrics to catch issues early
5. **Scale** your infrastructure when necessary

By following the techniques outlined in this guide, you'll be able to diagnose and resolve most Grafana performance issues, ensuring a smooth and responsive monitoring experience for your users.

## Additional Resources

- [Grafana Performance Tips](https://grafana.com/docs/grafana/latest/setup-grafana/optimize-grafana/)
- [Prometheus Query Optimization](https://prometheus.io/docs/prometheus/latest/querying/optimizing_query_performance/)
- [InfluxDB Query Performance](https://docs.influxdata.com/influxdb/v2/query-data/optimize-queries/)
- [Grafana Labs Blog - Dashboard Performance](https://grafana.com/blog/2021/01/14/how-to-optimize-grafana-dashboard-performance/)

## Exercises

1. **Performance Audit Exercise**
   - Take an existing dashboard and perform a performance audit
   - Identify at least three improvements that could be made
   - Implement and measure the improvements

2. **Query Optimization Challenge**
   - Optimize the following inefficient queries for better performance:
   ```
   # Prometheus
   rate(http_requests_total[1h])
   
   # InfluxDB
   SELECT * FROM "cpu" WHERE time > now() - 7d
   
   # SQL
   SELECT timestamp, value FROM metrics ORDER BY timestamp
   ```

3. **Dashboard Structure Exercise**
   - Redesign a complex dashboard with more than 30 panels
   - Break it down into multiple linked dashboards
   - Use template variables to maintain functionality across dashboards