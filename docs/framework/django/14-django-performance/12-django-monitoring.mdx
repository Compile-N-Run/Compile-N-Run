---
title: Django Monitoring
description: Learn how to monitor your Django application's performance to identify bottlenecks and ensure optimal user experience.

---

# Django Monitoring

Monitoring your Django application is a critical step in maintaining performance and reliability. This guide will walk you through the fundamentals of Django monitoring, essential tools, and best practices to ensure your web applications run smoothly.

## Introduction to Django Monitoring

Monitoring is the process of observing and tracking your application's performance metrics, resource usage, and behavior in real-time. For Django applications, effective monitoring allows you to:

- Identify performance bottlenecks
- Detect errors before users report them
- Track resource usage (CPU, memory, database connections)
- Plan for scaling needs
- Ensure optimal user experience

Without proper monitoring, you might be unaware of issues affecting your users until they become critical problems.

## Why Monitor Your Django Application?

Consider this scenario: your Django application works perfectly in development, but after deploying to production, users complain about slow page loads or occasional errors. Without monitoring, you'd need to manually hunt for the issue, which could take hours or days.

With proper monitoring in place, you could immediately see:
- Which views are slow
- If database queries are causing bottlenecks
- Memory or CPU spikes during certain operations
- Error rates and specific exception details

## Key Performance Metrics to Monitor

When monitoring Django applications, focus on these critical metrics:

### 1. Response Time
How long it takes for your application to respond to requests.

### 2. Error Rates
The percentage of requests that result in errors (4xx and 5xx responses).

### 3. Database Performance
Query execution times, number of queries per request, and connection pool usage.

### 4. Memory Usage
How much memory your Django processes are consuming.

### 5. CPU Utilization
The amount of CPU resources your application is using.

### 6. Request Throughput
The number of requests your application handles per minute/second.

## Monitoring Tools for Django

Let's explore some powerful tools for monitoring Django applications:

### 1. Django Debug Toolbar

The Django Debug Toolbar is an essential development tool that provides detailed information about the current request/response cycle.

#### Installation and Setup

```bash
pip install django-debug-toolbar
```

Add it to your installed apps:

```python
# settings.py
INSTALLED_APPS = [
    # ...
    'debug_toolbar',
    # ...
]

MIDDLEWARE = [
    # ...
    'debug_toolbar.middleware.DebugToolbarMiddleware',
    # ...
]

INTERNAL_IPS = [
    '127.0.0.1',
]
```

Then add it to your URLs:

```python
# urls.py
from django.urls import path, include
import debug_toolbar

urlpatterns = [
    # ...
    path('__debug__/', include(debug_toolbar.urls)),
]
```

The Debug Toolbar provides panels for:
- SQL queries
- Request timing
- Template rendering
- Cache usage
- And much more

However, remember that the Debug Toolbar is designed for development, not production environments.

### 2. Django Silk

Django Silk is a profiling tool that records requests and database queries.

#### Installation and Setup

```bash
pip install django-silk
```

Add it to your settings:

```python
INSTALLED_APPS = [
    # ...
    'silk',
]

MIDDLEWARE = [
    # ...
    'silk.middleware.SilkyMiddleware',
    # ...
]
```

Add it to your URLs:

```python
urlpatterns = [
    # ...
    path('silk/', include('silk.urls', namespace='silk')),
]
```

Silk provides an interface at `/silk/` where you can analyze requests, including:
- Time taken for each request
- Database queries executed
- Detailed profiling information

### 3. Prometheus with Django-Prometheus

For production monitoring, Prometheus is a powerful open-source monitoring solution that integrates well with Django.

```bash
pip install django-prometheus
```

```python
# settings.py
INSTALLED_APPS = [
    # ...
    'django_prometheus',
    # ...
]

MIDDLEWARE = [
    'django_prometheus.middleware.PrometheusBeforeMiddleware',
    # ... your other middleware ...
    'django_prometheus.middleware.PrometheusAfterMiddleware',
]
```

This setup exposes metrics at `/metrics` endpoint, which Prometheus can scrape. You can then visualize these metrics using Grafana dashboards.

### 4. Application Performance Monitoring (APM) Services

Several third-party APM services offer comprehensive monitoring solutions:

#### New Relic

New Relic provides detailed performance monitoring with an easy setup:

```bash
pip install newrelic
```

Create a newrelic.ini configuration file, and then run:

```bash
NEW_RELIC_CONFIG_FILE=newrelic.ini newrelic-admin run-program gunicorn myapp.wsgi
```

#### Datadog

Datadog offers APM capabilities specifically for Django:

```bash
pip install ddtrace
```

Run your application with:

```bash
DD_SERVICE="my-django-app" ddtrace-run python manage.py runserver
```

#### Sentry

Sentry excels at error tracking and provides performance monitoring:

```bash
pip install sentry-sdk
```

```python
# settings.py
import sentry_sdk
from sentry_sdk.integrations.django import DjangoIntegration

sentry_sdk.init(
    dsn="your-dsn-here",
    integrations=[DjangoIntegration()],
    traces_sample_rate=1.0,  # Adjust in production
)
```

## Custom Monitoring with Django Middleware

Sometimes you might need custom metrics. Let's create a middleware to measure response times:

```python
# monitoring/middleware.py
import time
import logging

logger = logging.getLogger(__name__)

class ResponseTimeMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        start_time = time.time()
        
        response = self.get_response(request)
        
        duration = time.time() - start_time
        logger.info(f"Path: {request.path} took {duration:.2f}s")
        
        # Could also send this to a monitoring service
        
        return response
```

Add this middleware to your settings:

```python
MIDDLEWARE = [
    # ...
    'myapp.monitoring.middleware.ResponseTimeMiddleware',
    # ...
]
```

## Monitoring Database Performance

Database operations are often the biggest performance bottlenecks. Here's how to monitor them:

### django-query-counter

This package counts the number of queries per request:

```bash
pip install django-query-counter
```

```python
# settings.py
MIDDLEWARE = [
    # ...
    'qc.middleware.QueryCountMiddleware',
]

# Configure thresholds
QUERY_COUNT = {
    'THRESHOLDS': {
        'MEDIUM': 50,
        'HIGH': 200,
        'EXTREME': 1000,
    }
}
```

### Writing a Query Logger

For more detailed logging of slow queries:

```python
# monitoring/database.py
import time
import logging
from django.db import connection
from django.db.backends.utils import CursorWrapper

logger = logging.getLogger(__name__)

class SlowQueryLoggingCursorWrapper(CursorWrapper):
    def execute(self, sql, params=None):
        start = time.time()
        try:
            return super().execute(sql, params)
        finally:
            duration = time.time() - start
            if duration > 0.1:  # Log queries taking more than 100ms
                logger.warning(f"Slow query ({duration:.2f}s): {sql}")

# In your settings, set up DB_ENGINE to use this wrapper
```

## Real-world Example: Monitoring a Django E-commerce Site

Let's see how monitoring would work in a real e-commerce application:

### Scenario: Slow Product Page

Users report that the product detail page is slow during peak hours. Here's how you'd approach this with monitoring:

1. Set up New Relic or a similar APM tool to track page load times.

2. Implement a custom middleware to measure view execution time:

```python
# monitoring/middleware.py
import time
from django.urls import resolve

class ViewPerformanceMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response
        
    def __call__(self, request):
        start_time = time.time()
        response = self.get_response(request)
        duration = time.time() - start_time
        
        # Get the view name
        try:
            route = resolve(request.path_info)
            view_name = route.func.__name__ if hasattr(route, 'func') else str(route.func)
            # Log or send to monitoring service
            if duration > 1.0:  # Log views taking more than 1 second
                print(f"Slow view {view_name} took {duration:.2f}s")
        except:
            pass
            
        return response
```

3. Add Django Silk to profile specific requests and identify slow database queries.

4. After analysis, you might discover that the product page is making too many database queries to load related products. The solution might be:

```python
# Before: N+1 query problem
def product_detail(request, product_id):
    product = Product.objects.get(id=product_id)
    # This causes a separate query for each related product
    related_products = product.related_products.all()
    return render(request, 'product_detail.html', {
        'product': product,
        'related_products': related_products,
    })

# After: Using select_related to solve the N+1 query problem
def product_detail(request, product_id):
    product = Product.objects.select_related('category').prefetch_related('related_products').get(id=product_id)
    return render(request, 'product_detail.html', {
        'product': product,
        'related_products': product.related_products.all(),  # No additional queries
    })
```

## Best Practices for Django Monitoring

1. **Start Early**: Implement basic monitoring from the beginning of your project.

2. **Monitor in Layers**:
   - Application level (views, middleware)
   - Database level (query performance)
   - System level (CPU, memory)
   - Infrastructure level (load balancers, caches)

3. **Set Up Alerts**: Establish thresholds and get notified when metrics cross them.

4. **Collect Only What You Need**: Too much data can be overwhelming and expensive.

5. **Combine Log Data with Metrics**: Often, logs provide context for unusual metrics.

6. **Monitor After Deployments**: Watch for performance changes after new releases.

7. **Consider User Experience Metrics**: Track front-end performance too (page load time, time to interactive).

## Summary

Django monitoring is an essential practice for maintaining performant applications. By keeping track of key metrics like response time, error rates, and resource usage, you can identify issues before they impact users and continuously optimize your application.

The tools we've covered - from Django Debug Toolbar and Silk for development to Prometheus and APM services for production - give you multiple options for monitoring, depending on your application's complexity and requirements.

Remember that monitoring should be an ongoing process, not a one-time setup. As your application evolves, your monitoring needs will change too.

## Additional Resources

- [Django Debug Toolbar Documentation](https://django-debug-toolbar.readthedocs.io/)
- [Django Silk Documentation](https://github.com/jazzband/django-silk)
- [Prometheus Documentation](https://prometheus.io/docs/introduction/overview/)
- [New Relic Python Agent Documentation](https://docs.newrelic.com/docs/apm/agents/python-agent/getting-started/introduction-new-relic-python)
- [Datadog APM for Django](https://docs.datadoghq.com/tracing/setup_overview/setup/python/)
- [Sentry for Django](https://docs.sentry.io/platforms/python/guides/django/)

## Exercises

1. Install Django Debug Toolbar in your development environment and analyze which views make the most database queries.

2. Create a custom middleware that logs views taking longer than 500ms to execute.

3. Set up Prometheus and Grafana to monitor a Django application and create a dashboard showing request rate, response times, and error rates.

4. Use Django Silk to profile a slow view and optimize it to reduce execution time by at least 50%.

5. Implement a health check endpoint in your Django application that reports on database connectivity, cache availability, and overall system health.