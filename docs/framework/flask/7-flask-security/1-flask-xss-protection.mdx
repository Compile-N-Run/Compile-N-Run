---
title: Flask XSS Protection
description: Learn how to protect your Flask applications from Cross-Site Scripting (XSS) attacks with practical examples and defensive coding techniques.

---

# Flask XSS Protection

## Introduction

Cross-Site Scripting (XSS) is one of the most common web application vulnerabilities that allows attackers to inject malicious client-side scripts into web pages viewed by other users. When your Flask application fails to properly sanitize user input, attackers can embed JavaScript code that executes in your users' browsers, potentially stealing cookies, session tokens, or other sensitive information.

In this guide, we'll explore how Flask helps protect against XSS attacks and what additional steps you should take to secure your application.

## Understanding XSS Vulnerabilities

XSS attacks typically fall into three categories:

1. **Reflected XSS**: Malicious script is reflected off the web server, such as in search results or error messages.
2. **Stored XSS**: The injected script is permanently stored on target servers, such as in a database.
3. **DOM-based XSS**: The vulnerability exists in client-side code rather than server-side code.

Let's see what an XSS vulnerability might look like in a Flask application:

```python
@app.route('/search')
def search():
    query = request.args.get('q', '')
    # Vulnerable code
    return f'<h1>Search results for: {query}</h1>'
```

If a user submits a query like `<script>alert('XSS')</script>`, the script would execute in the browser.

## Flask's Built-in Protection

Flask includes Jinja2 as its templating engine, which automatically escapes content placed into templates. This provides a basic level of XSS protection out-of-the-box.

### Automatic Escaping in Templates

When you use Jinja2 templates, variables are automatically escaped:

```python
@app.route('/search')
def search():
    query = request.args.get('q', '')
    # Safer - Jinja will escape the query
    return render_template('search.html', query=query)
```

In your `search.html` template:

```html
<h1>Search results for: {{ query }}</h1>
```

If a user submits `<script>alert('XSS')</script>` as the query, Jinja2 will automatically escape it to:

```
&lt;script&gt;alert('XSS')&lt;/script&gt;
```

This prevents the script from executing in the browser.

## Enhanced XSS Protection Techniques

### 1. Use Content Security Policy (CSP)

Content Security Policy is a powerful defense that can help prevent XSS attacks by specifying which dynamic resources are allowed to load.

Here's how to implement CSP in Flask using the `flask-talisman` extension:

```python
from flask import Flask
from flask_talisman import Talisman

app = Flask(__name__)

csp = {
    'default-src': '\'self\'',
    'script-src': '\'self\'',
    'style-src': '\'self\'',
}

Talisman(app, content_security_policy=csp)

@app.route('/')
def index():
    return render_template('index.html')
```

This configuration restricts resources to be loaded only from the same origin.

### 2. Explicitly Marking Safe Content

Sometimes you might want to include HTML content that you trust. Jinja2 provides a `safe` filter for this purpose, but use it cautiously:

```python
@app.route('/blog/<int:post_id>')
def show_post(post_id):
    post = get_post(post_id)  # Get the post from the database
    # Only mark as safe if the content is from trusted users or admins
    return render_template('post.html', content=post.content)
```

In your template:

```html
<!-- Only use the "safe" filter when you're certain the content is safe -->
<div class="post-content">{{ content|safe }}</div>
```

### 3. Input Validation and Sanitization

Always validate and sanitize user input before storing or displaying it:

```python
import bleach

@app.route('/comment', methods=['POST'])
def add_comment():
    comment = request.form.get('comment', '')
    # Sanitize input to remove harmful HTML/scripts
    clean_comment = bleach.clean(comment, 
                               tags=['p', 'b', 'i', 'u', 'a'], 
                               attributes={'a': ['href']})
    
    # Store the clean comment
    save_comment(clean_comment)
    return redirect(url_for('view_comments'))
```

This example uses the `bleach` library to strip potentially dangerous HTML while allowing a limited set of safe tags.

### 4. HTTP-Only and Secure Cookies

Protect your cookies from being accessed by client-side scripts:

```python
app.config.update(
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SECURE=True,  # Use only in HTTPS environments
    REMEMBER_COOKIE_HTTPONLY=True,
    REMEMBER_COOKIE_SECURE=True,
)
```

## Real-World Example: Secure Comment System

Let's build a complete example of a secure comment system that protects against XSS:

```python
from flask import Flask, request, render_template, redirect, url_for
from flask_wtf import FlaskForm
from wtforms import TextAreaField, SubmitField
from wtforms.validators import DataRequired
import bleach
from flask_talisman import Talisman

app = Flask(__name__)
app.config['SECRET_KEY'] = 'replace-with-a-secure-key'

# Setup Content Security Policy
csp = {
    'default-src': '\'self\'',
    'script-src': '\'self\'',
    'style-src': ['\'self\'', 'https://stackpath.bootstrapcdn.com'],
}
Talisman(app, content_security_policy=csp)

# In-memory storage for comments (use a database in production)
comments = []

class CommentForm(FlaskForm):
    content = TextAreaField('Comment', validators=[DataRequired()])
    submit = SubmitField('Post Comment')

@app.route('/', methods=['GET', 'POST'])
def index():
    form = CommentForm()
    if form.validate_on_submit():
        # Sanitize the comment content
        clean_content = bleach.clean(
            form.content.data,
            tags=['p', 'b', 'i', 'u', 'a'],
            attributes={'a': ['href']},
            strip=True
        )
        comments.append(clean_content)
        return redirect(url_for('index'))
    
    return render_template('comments.html', form=form, comments=comments)

if __name__ == '__main__':
    app.run(debug=True)
```

And the corresponding `comments.html` template:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Secure Comment System</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
</head>
<body>
    <div class="container mt-5">
        <h1>Comments</h1>
        
        <form method="post">
            {{ form.hidden_tag() }}
            <div class="form-group">
                {{ form.content.label }}
                {{ form.content(class="form-control") }}
            </div>
            {{ form.submit(class="btn btn-primary") }}
        </form>
        
        <hr>
        
        <h2>Previous Comments</h2>
        {% for comment in comments %}
            <div class="card mb-3">
                <div class="card-body">
                    {{ comment|safe }}
                </div>
            </div>
        {% endfor %}
    </div>
</body>
</html>
```

Notice that we mark the comment as `safe` because we've already sanitized it with Bleach. Without sanitization, using `safe` would be dangerous.

## Testing Your XSS Defenses

It's essential to test your XSS protections. Here are some common test payloads:

```
<script>alert('XSS')</script>
<img src="x" onerror="alert('XSS')">
<a href="javascript:alert('XSS')">Click me</a>
<div onmouseover="alert('XSS')">Hover over me</div>
```

When implementing your defenses correctly, these should either be escaped or sanitized.

## Summary

XSS vulnerabilities can have severe consequences for your application and its users. Fortunately, Flask, through Jinja2, provides robust automatic escaping. However, to create truly secure applications, you should:

1. **Never bypass automatic escaping** without sanitizing the content first
2. **Implement Content Security Policy** to restrict what can execute in users' browsers
3. **Validate and sanitize all user input** before storing or displaying it
4. **Use HTTP-only and secure flags** for cookies to protect sensitive information
5. **Regularly test your application** for XSS vulnerabilities

By following these practices, you'll significantly reduce the risk of XSS attacks against your Flask application.

## Additional Resources

- [OWASP XSS Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html)
- [Flask-Talisman Documentation](https://github.com/GoogleCloudPlatform/flask-talisman)
- [Bleach Documentation](https://bleach.readthedocs.io/)
- [Content Security Policy Reference](https://content-security-policy.com/)

## Exercises

1. Modify the comment system example to allow certain HTML tags but no JavaScript.
2. Create a Flask route that safely displays user-submitted markdown content.
3. Implement CSP reporting to collect information about potential XSS attempts.
4. Build a Flask extension that automatically sanitizes form inputs before processing.